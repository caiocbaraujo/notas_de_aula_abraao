# Página n10 - Regressão Linear Simples

## Modelo de Regressão

### Equação do Modelo
$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

onde:
- $Y_i$ = variável dependente
- $X_i$ = variável independente
- $\beta_0$ = intercepto
- $\beta_1$ = coeficiente angular
- $\varepsilon_i \sim N(0, \sigma^2)$

## Estimadores dos Mínimos Quadrados

### Coeficiente Angular
$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2} = \frac{S_{XY}}{S_{XX}}$$

### Intercepto
$$\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}$$

## Propriedades dos Estimadores

### Distribuições
$$\hat{\beta}_1 \sim N\left(\beta_1, \frac{\sigma^2}{S_{XX}}\right)$$

$$\hat{\beta}_0 \sim N\left(\beta_0, \sigma^2\left(\frac{1}{n} + \frac{\bar{X}^2}{S_{XX}}\right)\right)$$

### Estimador da Variância
$$S^2 = \frac{SSE}{n-2} = \frac{\sum_{i=1}^n (Y_i - \hat{Y}_i)^2}{n-2}$$

## Coeficiente de Determinação
$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$

onde:
- $SSR$ = soma dos quadrados da regressão
- $SSE$ = soma dos quadrados dos erros
- $SST$ = soma total dos quadrados
