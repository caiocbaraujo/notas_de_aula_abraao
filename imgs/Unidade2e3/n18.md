# Página n18 - Validação Cruzada e Seleção de Modelos

## Validação Cruzada

### K-Fold Cross-Validation
1. Dividir dados em $k$ grupos de tamanho aproximadamente igual
2. Treinar modelo em $k-1$ grupos
3. Testar no grupo restante
4. Repetir para todos os $k$ grupos
5. Calcular erro médio

### Leave-One-Out Cross-Validation (LOOCV)
Caso especial onde $k = n$ (cada observação é um grupo).

### Erro de Validação Cruzada
$$CV_{(k)} = \frac{1}{k} \sum_{i=1}^k \text{MSE}_i$$

## Critérios de Seleção de Modelos

### AIC (Akaike Information Criterion)
$$AIC = -2 \log L + 2p$$

onde $p$ = número de parâmetros.

### BIC (Bayesian Information Criterion)
$$BIC = -2 \log L + p \log n$$

### Critério de Mallow's Cp
$$C_p = \frac{SSE_p}{S^2} - n + 2p$$

onde $SSE_p$ = soma dos quadrados dos erros do modelo com $p$ parâmetros.

## Regularização

### Ridge Regression
$$\hat{\boldsymbol{\beta}}^{ridge} = \arg\min_{\boldsymbol{\beta}} \left\{\sum_{i=1}^n (y_i - \mathbf{x}_i^T \boldsymbol{\beta})^2 + \lambda \sum_{j=1}^p \beta_j^2\right\}$$

### Lasso Regression
$$\hat{\boldsymbol{\beta}}^{lasso} = \arg\min_{\boldsymbol{\beta}} \left\{\sum_{i=1}^n (y_i - \mathbf{x}_i^T \boldsymbol{\beta})^2 + \lambda \sum_{j=1}^p |\beta_j|\right\}$$

### Elastic Net
Combinação de Ridge e Lasso com parâmetros $\alpha$ e $\lambda$.

## Seleção de Variáveis
- Forward selection
- Backward elimination  
- Stepwise regression
- Best subset selection
